import streamlit as st
import requests
import PyPDF2
import difflib
from fpdf import FPDF
from io import BytesIO
import hashlib
from datetime import datetime

# URLs das APIs
SEMANTIC_API = "https://api.semanticscholar.org/graph/v1/paper/search"
CROSSREF_API = "https://api.crossref.org/works"
URL_GOOGLE_SHEETS = "https://script.google.com/macros/s/AKfycbyTpbWDxWkNRh_ZIlHuAVwZaCC2ODqTmo0Un7ZDbgzrVQBmxlYYKuoYf6yDigAPHZiZ/exec"

# =============================
# üìã Fun√ß√£o para Salvar E-mails e C√≥digo de Verifica√ß√£o no Google Sheets
# =============================
def salvar_email_google_sheets(nome, email, codigo_verificacao):
    dados = {
        "nome": nome,
        "email": email,
        "codigo": codigo_verificacao
    }
    try:
        headers = {'Content-Type': 'application/json'}
        response = requests.post(URL_GOOGLE_SHEETS, json=dados, headers=headers)

        if response.text.strip() == "Sucesso":
            st.success("‚úÖ E-mail, nome e c√≥digo registrados com sucesso!")
        else:
            st.error(f"‚ùå Erro ao salvar dados no Google Sheets: {response.text}")
    except Exception as e:
        st.error(f"‚ùå Erro na conex√£o com o Google Sheets: {e}")

# =============================
# üîé Fun√ß√£o para Verificar C√≥digo de Verifica√ß√£o na Planilha
# =============================
def verificar_codigo_google_sheets(codigo_digitado):
    try:
        response = requests.get(f"{URL_GOOGLE_SHEETS}?codigo={codigo_digitado}")
        if response.text.strip() == "Valido":
            return True
        else:
            return False
    except Exception as e:
        st.error(f"‚ùå Erro na conex√£o com o Google Sheets: {e}")
        return False

# =============================
# üîê Fun√ß√£o para Gerar C√≥digo de Verifica√ß√£o
# =============================
def gerar_codigo_verificacao(texto):
    return hashlib.md5(texto.encode()).hexdigest()[:10].upper()

# =============================
# üìù Fun√ß√£o para Extrair Texto do PDF
# =============================
def extrair_texto_pdf(arquivo_pdf):
    leitor_pdf = PyPDF2.PdfReader(arquivo_pdf)
    texto = ""
    for pagina in leitor_pdf.pages:
        texto += pagina.extract_text() or ""
    return texto.strip()

# =============================
# üìä Fun√ß√£o para Calcular Similaridade
# =============================
def calcular_similaridade(texto1, texto2):
    seq_matcher = difflib.SequenceMatcher(None, texto1, texto2)
    return seq_matcher.ratio()

# =============================
# üîé Fun√ß√£o para Buscar Artigos na API CrossRef
# =============================
def buscar_referencias_crossref(texto):
    query = "+".join(texto.split()[:10])  # Usa as primeiras 10 palavras para a busca
    url = f"{CROSSREF_API}?query={query}&rows=10"

    try:
        response = requests.get(url)
        response.raise_for_status()
        data = response.json()
    except requests.exceptions.RequestException as e:
        st.error(f"Erro ao acessar a API da CrossRef: {e}")
        return []

    referencias = []
    for item in data.get("message", {}).get("items", []):
        titulo = item.get("title", ["T√≠tulo n√£o dispon√≠vel"])[0]
        resumo = item.get("abstract", "")
        link = item.get("URL", "Link n√£o dispon√≠vel")
        referencias.append({"titulo": titulo, "resumo": resumo, "link": link})

    return referencias

# =============================
# üîé Fun√ß√£o para Buscar Artigos na API Semantic Scholar
# =============================
def buscar_referencias_semantic_scholar(texto):
    query = "+".join(texto.split()[:10])  # Usa as primeiras 10 palavras para a busca
    url = f"{SEMANTIC_API}?query={query}&limit=10"

    try:
        response = requests.get(url)
        response.raise_for_status()
        data = response.json()
    except requests.exceptions.RequestException as e:
        st.error(f"Erro ao acessar a API da Semantic Scholar: {e}")
        return []

    referencias = []
    for item in data.get("data", []):
        titulo = item.get("title", "T√≠tulo n√£o dispon√≠vel")
        resumo = item.get("abstract", "")
        link = item.get("url", "Link n√£o dispon√≠vel")
        referencias.append({"titulo": titulo, "resumo": resumo, "link": link})

    return referencias

# =============================
# üîé Fun√ß√£o para Buscar Refer√™ncias Combinadas (CrossRef + Semantic Scholar)
# =============================
def buscar_referencias(texto):
    # Busca na CrossRef
    referencias_crossref = buscar_referencias_crossref(texto)
    
    # Busca na Semantic Scholar
    referencias_semantic = buscar_referencias_semantic_scholar(texto)
    
    # Combina os resultados
    referencias = referencias_crossref + referencias_semantic
    
    # Remove duplicatas (se houver)
    referencias_unicas = []
    titulos_vistos = set()
    for ref in referencias:
        if ref["titulo"] not in titulos_vistos:
            referencias_unicas.append(ref)
            titulos_vistos.add(ref["titulo"])
    
    return referencias_unicas

# =============================
# üìÑ Fun√ß√£o para Gerar Relat√≥rio PDF
# =============================
class PDF(FPDF):
    def header(self):
        self.set_font('Arial', 'B', 16)
        self.cell(0, 10, "Relat√≥rio de Similaridade de Pl√°gio - PlagIA - PEAS.Co", ln=True, align='C')

    def chapter_title(self, title):
        self.set_font('Arial', 'B', 12)
        self.cell(0, 10, self._encode_text(title), ln=True)
        self.ln(3)

    def chapter_body(self, body):
        self.set_font('Arial', '', 10)
        self.multi_cell(0, 8, self._encode_text(body))
        self.ln()

    # üîé Fun√ß√£o para corrigir acentua√ß√£o e caracteres especiais
    def _encode_text(self, text):
        try:
            return text.encode('latin-1', 'replace').decode('latin-1')
        except UnicodeEncodeError:
            return ''.join(char if ord(char) < 128 else '?' for char in text)

def gerar_relatorio_pdf(referencias_com_similaridade, nome, email, codigo_verificacao):
    pdf = PDF()
    pdf.add_page()

    # Adicionando os dados do usu√°rio no PDF
    data_hora = datetime.now().strftime("%d/%m/%Y %H:%M:%S")
    pdf.chapter_title("Dados do Solicitante:")
    pdf.chapter_body(f"Nome: {nome}")
    pdf.chapter_body(f"E-mail: {email}")
    pdf.chapter_body(f"Data e Hora: {data_hora}")
    pdf.chapter_body(f"C√≥digo de Verifica√ß√£o: {codigo_verificacao}")
    
    # Refer√™ncias encontradas
    pdf.chapter_title("Top 5 Refer√™ncias encontradas:")

    soma_percentual = 0
    for i, (ref, perc, link) in enumerate(referencias_com_similaridade[:5], 1):
        soma_percentual += perc
        pdf.chapter_body(f"{i}. {ref} - {perc*100:.2f}%\n{link}")

    pl√°gio_medio = (soma_percentual / 5) * 100
    pdf.chapter_body(f"Pl√°gio m√©dio: {pl√°gio_medio:.2f}%")

    pdf_file_path = "/tmp/relatorio_plagio.pdf"
    pdf.output(pdf_file_path, 'F')

    return pdf_file_path

# =============================
# üíª Interface do Streamlit
# =============================
if __name__ == "__main__":
    st.title("PlagIA - PEAS.Co")

    st.subheader("üìã Registro de Usu√°rio - Apenas para valida√ß√£o")
    nome = st.text_input("Nome completo")
    email = st.text_input("E-mail")

    if st.button("Salvar Dados"):
        if nome and email:
            salvar_email_google_sheets(nome, email, "N/A")
        else:
            st.warning("‚ö†Ô∏è Por favor, preencha todos os campos.")

    # Upload do PDF ap√≥s registro
    arquivo_pdf = st.file_uploader("Fa√ßa upload de um arquivo PDF sem os nomes dos autores ou t√≠tulo da revista", type=["pdf"])

    if st.button("Processar PDF"):
        if arquivo_pdf is not None:
            texto_usuario = extrair_texto_pdf(arquivo_pdf)
            referencias = buscar_referencias(texto_usuario)  # Usa a nova fun√ß√£o combinada

            referencias_com_similaridade = []
            for ref in referencias:
                texto_base = ref["titulo"] + " " + ref["resumo"]
                link = ref["link"]
                similaridade = calcular_similaridade(texto_usuario, texto_base)
                referencias_com_similaridade.append((ref["titulo"], similaridade, link))

            referencias_com_similaridade.sort(key=lambda x: x[1], reverse=True)

            if referencias_com_similaridade:
                codigo_verificacao = gerar_codigo_verificacao(texto_usuario)
                salvar_email_google_sheets(nome, email, codigo_verificacao)

                st.success(f"C√≥digo de verifica√ß√£o gerado: **{codigo_verificacao}**")

                # Gerar e exibir link para download do relat√≥rio
                pdf_file = gerar_relatorio_pdf(referencias_com_similaridade, nome, email, codigo_verificacao)
                with open(pdf_file, "rb") as f:
                    st.download_button("üìÑ Baixar Relat√≥rio de Pl√°gio", f, "relatorio_plagio.pdf")
            else:
                st.warning("Nenhuma refer√™ncia encontrada.")
        else:
            st.error("Por favor, carregue um arquivo PDF.")

    # Verifica√ß√£o de c√≥digo
    st.header("Verificar Autenticidade")
    codigo_digitado = st.text_input("Digite o c√≥digo de verifica√ß√£o:")

    if st.button("Verificar C√≥digo"):
        if verificar_codigo_google_sheets(codigo_digitado):
            st.success("‚úÖ Documento Aut√™ntico e Original!")
        else:
            st.error("‚ùå C√≥digo inv√°lido ou documento falsificado.")

    # Texto explicativo ao final da p√°gina
    st.markdown("""
    ---
    Nosso avan√ßado programa de detec√ß√£o de pl√°gio utiliza intelig√™ncia artificial para comparar textos com uma ampla base de dados composta pelos 100 maiores indexadores e reposit√≥rios globais, analisando cuidadosamente as similaridades encontradas. Com base em estudos internacionais, considera-se que uma taxa de similaridade de 3% ou mais indica uma alta concentra√ß√£o de trechos raros ‚Äî ou seja, sequ√™ncias de palavras pouco frequentes que apontam para uma poss√≠vel c√≥pia. Para ilustrar o processo de an√°lise documental, imagine que um arquivo A tenha sido integralmente copiado de outro arquivo B. Ainda assim, a similaridade pode ser igual ou inferior a 50%, e n√£o 100%, devido √† varia√ß√£o na quantidade de trechos considerados na compara√ß√£o. Pesquisas demonstram que uma taxa m√©dia de 3% ou mais costuma indicar uma elevada incid√™ncia de termos semelhantes, configurando, assim, uma poss√≠vel ocorr√™ncia de pl√°gio. √â importante ressaltar que a avalia√ß√£o final sobre a presen√ßa de pl√°gio cabe sempre aos autores e respons√°ves pelo conte√∫do.Para mais informa√ß√µes sobre pr√°ticas de integridade acad√™mica, acesse [plagiarism.org](https://plagiarism.org). Powered By - PEAS.Co
    """)
